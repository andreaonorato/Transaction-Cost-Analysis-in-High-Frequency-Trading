ðŸ“… Week 1: Dataset Collection & Preprocessing
Goal: Find and prepare the dataset(s) for analysis.

Day 1â€“2: Dataset Identification
    Centralized Dataset:
        https://github.com/hank08819/HFTTradingMAP (1 minute data of most famous Stock) then we need to simulate investments and commissions
https://www.kaggle.com/datasets/wentinglu/highfrequency-futures-data-china (1 minute data of most famous chineses Stock) then we need to simulate investments and commissions
https://firstratedata.com/free-intraday-data (1 minute data but only for 2 weeks) - only for SPY and EEM ETFs
https://etsin.fairdata.fi/dataset/73eb48d7-4dbc-4a10-a52a-da745b47a649/data (1 minute data I think)

    Decentralized Dataset:
Etherscan API works well for what we need (example of use in the main.py). We can pick 1000 ETH address (both HFT investors and passive investors) and see how they performed (you can see buy and sell transactions and estimate the returns in USD for example
Uniswap is also good for the same purpose and you can check different crypto, not only ETH
>>>>>>> 144ae532d7d413daf0c7d44361efbb790c0dca51 etherscan address example

Deliverables:
    Links to selected datasets. - All grouped selected dataset - https://mega.nz/folder/AOcCAS4Q#whnWw3j81doBSmpBWAWDxw
    Initial inspection of datasets (data types, size, structure). - present in the EDA Notebook file

Day 3â€“5: Data Preprocessing
    Standardize Data: Align columns (timestamp    open    high     low   close  volume  Centralized/Decentralized).
    Merge Data: Merge all dataset data with a column called (Dataset_name and a binary column for centralized/decentralized and file name)
    Active vs Passive Labels: Define thresholds for active and passive trades.
Deliverables:
    Cleaned dataset(s) ready for analysis.
    Data preprocessing script.

ðŸ“… Week 2: Analysis & Modeling
Goal: Conduct statistical analysis, build regression models, and simulate scenarios.

Day 6â€“8: Statistical Analysis
    Regression Analysis: Trade frequency, commission rates, and net returns.
    Performance Metrics: Calculate Sharpe Ratio, Net Returns.
    Epps Effect: Examine return correlations over time.
Deliverables:
    Statistical summary and key relationships identified.
    Visualizations (scatter plots, regression lines).

Day 9â€“11: Simulation & Scenario Modeling
    Build simulations for varying:
        Trade frequency
        Investment size
        Commission fees
    Compare outcomes across centralized vs decentralized exchanges.
Deliverables:
    Simulation outputs and visualizations.
    Key insights documented.

Day 12â€“14: Theoretical Model Integration
    Bouchaud's Response Function: Model price impact across exchanges.
    Volatility Clustering (GARCH Model): Assess risk-adjusted returns.
    Epps Effect: Validate theoretical predictions with data.
Deliverables:
    Results from Bouchaud's model and GARCH analysis.
    Final visualizations showing trade-offs.

ðŸ“… Week 3: Results & Write-Up
Goal: Organize results and draft the paper.

Day 15â€“17: Write-Up Drafting
    Already on overleaf how to do it (10 pages text and max 15 comprehending images)
Deliverables:
    First full draft of the paper.
    Clear figures and tables.

Day 18: Code Cleanup
    Create a main.py file that:
        Runs the full analysis.
        Has a Boolean switch for demo mode (subset of data).
    Organize folders:
        /data (demo data + README for full dataset link).
        /scripts (preprocessing, analysis, simulation).
        /outputs (graphs, tables).
Deliverables:
    Main code file (main.py) with demo switch.
    README file explaining the folder structure and dependencies.

Day 19: Final Submission
    Double-check:
        Write-up is clean and formatted.
        Code runs without errors in demo mode.
        Dataset links are clearly provided.
